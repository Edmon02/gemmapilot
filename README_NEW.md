# ğŸš€ GemmaPilot - Advanced AI Coding Assistant

> **Now Enhanced!** GemmaPilot v0.1.0 brings GitHub Copilot-level features with advanced capabilities like file analysis, command execution, and beautiful chat UI - all running locally!

GemmaPilot is a powerful AI coding assistant for VS Code that provides intelligent code suggestions, explanations, and assistance using local language models via Ollama. Unlike cloud-based solutions, GemmaPilot keeps your code private and secure on your machine.

## âœ¨ New Features in v0.1.0

### ğŸ¯ Core AI Capabilities
- **ğŸ’¬ Context-Aware Chat**: Intelligent conversations with full workspace awareness
- **ğŸ“„ File Analysis**: Deep code analysis and detailed explanations  
- **âš¡ Code Completion**: Smart autocomplete suggestions with context
- **ğŸ“ File Attachment**: Attach and analyze specific files in chat
- **ğŸŒ Workspace Integration**: Access and analyze your entire project structure
- **âš™ï¸ Command Execution**: Run terminal commands with AI assistance (user approval required)

### ğŸ¨ Beautiful Interface
- **Modern WebView UI**: Clean, responsive chat interface with toolbar
- **ğŸ“ Markdown & Code Rendering**: Properly formatted responses with syntax highlighting
- **ğŸ›ï¸ Context Controls**: Toggle workspace, selection, and file context
- **ğŸ”§ Professional Design**: GitHub-inspired styling with dark theme support

### ğŸ”’ Privacy & Security
- **ğŸ  Local Processing**: Uses your own Ollama instance - no data leaves your machine
- **âœ… Command Approval**: User confirmation required for all command executions
- **ğŸ›¡ï¸ Safe Filtering**: Dangerous commands automatically blocked
- **ğŸ” Zero Data Sharing**: Everything stays on your computer

## ğŸš€ Quick Start

### Installation
1. **Install Ollama**: [Download from ollama.ai](https://ollama.ai)
2. **Pull a Model**: `ollama pull codellama:7b`
3. **Install Dependencies**: `pip install fastapi uvicorn ollama pydantic`
4. **Start Backend**: `cd backend && python server.py`
5. **Install Extension**: Load `gemmapilot-0.1.0.vsix` in VS Code
6. **Open Chat**: `Ctrl+Shift+P` â†’ "GemmaPilot: Open Chat"

### Usage Examples
- **ğŸ’¡ Ask Questions**: "Explain this function" or "How can I optimize this code?"
- **ğŸ“ Analyze Files**: Attach files and ask "What does this code do?"
- **ğŸ” Context Help**: Select code and ask "Refactor this function"
- **âš¡ Get Commands**: "Run the tests" or "Install dependencies" (with approval)

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP/REST    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VS Code       â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ FastAPI Backend  â”‚
â”‚   Extension     â”‚                 â”‚                  â”‚
â”‚                 â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                 â”‚ â”‚   Ollama     â”‚ â”‚
â”‚ â”‚ WebView UI  â”‚ â”‚                 â”‚ â”‚   (Local LLM)â”‚ â”‚
â”‚ â”‚ (Chat)      â”‚ â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Frontend**: TypeScript VS Code extension with WebView UI
- **Backend**: FastAPI server with Ollama integration  
- **AI Model**: Local Ollama instance (codellama, gemma3, etc.)
- **Communication**: REST API for all interactions

## ğŸ› ï¸ Available Features

| Feature | Description | Status |
|---------|-------------|--------|
| ğŸ’¬ **Enhanced Chat** | Context-aware conversations with workspace integration | âœ… Ready |
| ğŸ“ **File Attachment** | Attach and analyze specific files | âœ… Ready |
| ğŸŒ **Workspace Context** | Full project structure awareness | âœ… Ready |
| ğŸ¯ **Selection Context** | Analyze selected code snippets | âœ… Ready |
| âš™ï¸ **Command Execution** | Run AI-suggested terminal commands | âœ… Ready |
| ğŸ“„ **File Analysis** | Deep code analysis and explanations | âœ… Ready |
| âš¡ **Code Completion** | Smart autocomplete suggestions | âœ… Ready |
| ğŸ¨ **Beautiful UI** | Modern WebView interface | âœ… Ready |

## ğŸ¯ Prerequisites

- **Hardware**: MacBook with Apple Silicon (M1/M2/M3) recommended, 16GB+ RAM
- **Software**:
  - macOS Ventura+ or Windows 10+ or Linux
  - Visual Studio Code 1.80.0+
  - Python 3.8+
  - Node.js 16+ (for development)

## ğŸ“ Project Structure

```
gemmapilot/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ USAGE_GUIDE.md              # Comprehensive usage guide
â”œâ”€â”€ ENHANCEMENT_COMPLETE.md     # Enhancement summary
â”œâ”€â”€ .gitignore                  # Professional gitignore
â”œâ”€â”€ setup.sh                    # Automated setup script
â”œâ”€â”€ test_features.py            # Feature testing script
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â””â”€â”€ server.py              # Enhanced server with all features
â””â”€â”€ extension/                  # VS Code extension
    â”œâ”€â”€ src/                   # TypeScript source
    â”‚   â”œâ”€â”€ extension.ts       # Main extension logic
    â”‚   â”œâ”€â”€ types.ts          # Type definitions
    â”‚   â”œâ”€â”€ config.ts         # Configuration
    â”‚   â””â”€â”€ statusBar.ts      # Status bar integration
    â”œâ”€â”€ package.json           # Extension manifest
    â””â”€â”€ gemmapilot-0.1.0.vsix # Ready-to-install extension
```

## ğŸ”§ Supported Languages

- **Primary**: Python, JavaScript/TypeScript, Go, Rust
- **Secondary**: Java, C/C++, PHP, Ruby, Swift
- **Markup**: HTML, CSS, Markdown, JSON, YAML
- **Databases**: SQL, MongoDB queries
- **DevOps**: Docker, Kubernetes, Shell scripts

## ğŸ› ï¸ Troubleshooting

### Backend Issues
```bash
# Check if backend is running
curl -X GET http://localhost:8000/health

# Test chat functionality  
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt":"Hello", "context":"test"}'
```

### Extension Issues
1. **Reload VS Code**: `Ctrl+Shift+P` â†’ "Developer: Reload Window"
2. **Check Extension**: Look for GemmaPilot icon in Activity Bar
3. **Reinstall**: Uninstall and reinstall the VSIX file
4. **Debug**: `Help` â†’ `Toggle Developer Tools` for console logs

### Performance Tips
- Use smaller models for faster responses: `ollama pull codellama:7b`
- Close other memory-intensive applications
- Monitor Ollama with `ollama ps`

## ğŸ§ª Testing

Run comprehensive feature tests:
```bash
# Test all backend features
python test_features.py

# Expected output:
# ğŸš€ GemmaPilot Backend Feature Tests
# âœ“ Chat endpoint working
# âœ“ Code completion working  
# âœ“ File analysis working
# âœ“ Workspace file listing working
# âœ“ Command execution working
# ğŸ‰ All tests passed!
```

## ğŸ”’ Security Features

- **Local Processing**: All AI inference happens on your machine
- **Command Filtering**: Dangerous commands (rm -rf, format, etc.) blocked
- **User Approval**: All command executions require explicit user consent
- **No Telemetry**: No usage data sent anywhere
- **Sandboxed**: Commands run in specified workspace directory only

## ğŸ†š vs GitHub Copilot

| Feature | GitHub Copilot | GemmaPilot | Advantage |
|---------|----------------|------------|-----------|
| Code Completion | âœ… | âœ… | Equal |
| Chat Interface | âœ… | âœ… | Equal |
| File Analysis | âœ… | âœ… | Equal |
| Context Awareness | âœ… | âœ… | Equal |
| **Command Execution** | âŒ | âœ… | ğŸ† GemmaPilot |
| **File Attachment** | âŒ | âœ… | ğŸ† GemmaPilot |
| **Local Processing** | âŒ | âœ… | ğŸ† GemmaPilot |
| **Custom Models** | âŒ | âœ… | ğŸ† GemmaPilot |
| **Open Source** | âŒ | âœ… | ğŸ† GemmaPilot |
| **Free** | âŒ | âœ… | ğŸ† GemmaPilot |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and test thoroughly
4. Commit: `git commit -m 'Add amazing feature'`
5. Push: `git push origin feature/amazing-feature`
6. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- **Ollama** for excellent local LLM serving
- **VS Code** for the powerful extension API
- **FastAPI** for the robust backend framework
- **GitHub Copilot** for inspiration and reference

## ğŸ†˜ Support & Documentation

- **Usage Guide**: See `USAGE_GUIDE.md` for comprehensive documentation
- **API Documentation**: Visit `http://localhost:8000/docs` when backend is running
- **Issues**: Report bugs and feature requests on GitHub
- **Discussions**: Join our community discussions

---

**Experience the future of AI-assisted coding - locally, privately, and powerfully! ğŸš€**

*Built with â¤ï¸ for developers who value privacy, control, and cutting-edge AI assistance.*
